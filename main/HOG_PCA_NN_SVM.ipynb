{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#HOG + PCA + NN + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Availability :  True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "DEVICES=tf.config.experimental.list_physical_devices()\n",
    "tf.config.experimental.set_memory_growth(device=DEVICES[1],enable=True)\n",
    "print('GPU Availability : ',tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet-50 PCA\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import imutils\n",
    "import argparse\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential    \n",
    "from tensorflow.keras.optimizers import RMSprop,Adam,SGD\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten,Input,InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import exposure,util,feature \n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn import svm, metrics, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcaimg(image):\n",
    "    blue, green, red = cv2.split(image)\n",
    "    df_red = red/255\n",
    "    df_blue = blue/255\n",
    "    df_green = green/255\n",
    "    pca_b = PCA(n_components=50)\n",
    "    pca_b.fit(df_blue)\n",
    "    trans_pca_b = pca_b.transform(df_blue)\n",
    "    \n",
    "    pca_g = PCA(n_components=50)\n",
    "    pca_g.fit(df_green)\n",
    "    trans_pca_g = pca_g.transform(df_green)\n",
    "    \n",
    "    pca_r = PCA(n_components=50)\n",
    "    pca_r.fit(df_red)\n",
    "    trans_pca_r = pca_r.transform(df_red)    \n",
    "    \n",
    "    b_arr = pca_b.inverse_transform(trans_pca_b)\n",
    "    g_arr = pca_g.inverse_transform(trans_pca_g)\n",
    "    r_arr = pca_r.inverse_transform(trans_pca_r)\n",
    "    \n",
    "    img_reduced = (cv2.merge((b_arr, g_arr, r_arr)))\n",
    "    \n",
    "    return img_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOG(imagePath,size):\n",
    "    H=[]\n",
    "    image = cv2.imread(imagePath)\n",
    "    imagem = cv2.bitwise_not(image)\n",
    "    imS = cv2.resize(image, (size, size))\n",
    "    gray = cv2.cvtColor(imS, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.3, tileGridSize=(8,8))\n",
    "    img = clahe.apply(gray) \n",
    "    #gray = cv2.cvtColor(imS, cv2.COLOR_BGR2GRAY)\n",
    "    (H, hogImage) = hog(img, orientations=9, pixels_per_cell=(17, 17),cells_per_block=(2,2), transform_sqrt=True, block_norm=\"L1\", visualize=True) \n",
    "    #Data Normalisation (Normalising HOG Features)\n",
    "    H*=10\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "data = []\n",
    "labels = []\n",
    "traindir='./path/Dataset/Vrindhaavan_overall_backup/Vrindavan_overall/'#Enter the Train Directory\n",
    "for directory_path in glob.glob(traindir+\"/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path,\"*.png\")):\n",
    "        #print(img_path)\n",
    "        A = HOG(img_path,SIZE)\n",
    "        #H*=10 #data Normalisation\n",
    "        data.append(A)\n",
    "        labels.append(label)\n",
    "np.save('./HOG_NN/data.npy',data)\n",
    "np.save('./HOG_NN/labels.npy',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load('./HOG_NN/data.npy')\n",
    "labels=np.load('./HOG_NN/labels.npy')\n",
    "#Data Normalisation (Normalising HOG Features)\n",
    "#data=np.array(data)*10\n",
    "# partition the data into training and testing \n",
    "(trainX, testX, trainY, testY) = train_test_split(data,labels,test_size=0.2,random_state=100)                                                                                                                 \n",
    "train_labels= trainY \n",
    "test_labels= testY\n",
    "#encode the labels (which are currently strings) as integers and then one-hot encode them\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(trainY)\n",
    "train_onehot= le.transform(trainY)\n",
    "le.fit(testY)\n",
    "test_onehot= le.transform(testY)\n",
    "#One hot encode y values for neural network.\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#labels = to_categorical(labels)\n",
    "#One hot encode y values for neural network. Not needed for Random Forest\n",
    "y_train = to_categorical(trainY)\n",
    "y_test = to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13151, 7056) \n",
      " (3288, 7056) \n",
      " (13151,) \n",
      " (3288,) \n",
      " (13151, 6719) \n",
      " (3288, 6719) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "trainX.shape,'\\n',\n",
    "testX.shape,'\\n',\n",
    "trainY.shape,'\\n',\n",
    "testY.shape,'\\n',\n",
    "y_train.shape,'\\n',\n",
    "y_test.shape,'\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(*Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16439\n",
      "(16439, 1096)\n"
     ]
    }
   ],
   "source": [
    "data=np.load('./HOG_NN/data.npy')\n",
    "labels=np.load('./HOG_NN/labels.npy')\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "toh= le.transform(labels)\n",
    "train_Y=to_categorical(toh)\n",
    "print(len(toh))\n",
    "print(toh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cum variance')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlYklEQVR4nO3deXwddb3/8dcnSZN0ydIt6Zou0AItW0tpQVFBdpRF4XpBUASkXBEvbvwuXr1cQK8/hZ/Lz3tRL2pVEGW7KlUqyNKyiNCNtnQhbWhLm25JtyRtmmY5n/vHTNrTkLany8mck3k/H4/DmfnOnJnPtyfM58z3O/Mdc3dERCS+cqIOQEREoqVEICISc0oEIiIxp0QgIhJzSgQiIjGXF3UAh2rAgAE+cuTIqMMQEckq8+bN2+zuAztblnWJYOTIkcydOzfqMEREsoqZvbu/ZWoaEhGJOSUCEZGYUyIQEYk5JQIRkZhTIhARibm0JQIzm2ZmNWa2eD/Lzcx+ZGZVZrbIzCamKxYREdm/dJ4R/Aq46ADLLwbGhK+pwE/SGIuIiOxH2u4jcPeXzWzkAVa5HHjIg3GwXzezUjMb7O4b0hWTiKRHIuG0JpyEB+9tbU6bO62JBG0Jpy3huIM7JNzDF0DwnnAnkQDHk9YJ3oPPHWCe9vL2bSTNd9gnBPPt+wmmg+0F0QT/2bM8rJ93LAv3u2dZOL/vZ967v/Z9vKdsn3U7/wzunHtCOacMLz2aXx0Q7Q1lQ4G1SfPVYdl7EoGZTSU4a6CioqJLghPprppa2qip383Wxma2NzazvbGF7Y3NbGtsoW5XMF23q4XG5jaaWhM0NbfR1NrGruY2WtoSwYE+6dWa0DNNukpZcWG3SwQpc/cHgQcBJk2apL86kU60JZxN9U2s376LTfW72VTfRE3Dbmrqm9jU0ERNWFbf1LrfbRQX5lHaK5+Snj3omZ9Lac8eFBYXUNgjl549cumRm0NerpFrRm74npdj5ObkkJsDuTk55OUYOTnt5eHLDDPIMSMnJ3iHcN6MHAMzsKT5HDNo/0z4brSvAzk5HeaT9tHxPccA2t+DzwSfBSNYr117HMnL95QHm9nzGaPz7WHs85nk5cEm9u6zYwwd17fk4NIkykSwDhieND8sLBORTrS0JdhY10T1tl1Ub2tk3fZdVG/bxbptu6je3siG7U3v+XXeI9coKyqkrLiA0QN7c+Yx/SkrKqCsqJD+ffIp7dWD0l759O2VT3FhHnm5upAwjqJMBNOB28zsUWAKUKf+AYm7RMJZX7eLVZt3snrzTlaG76s272Tttl20JR3ozaC8qJChfXsysaIvQ0/uybC+vRhSWsigkkLKigrp26tHl/yilOyWtkRgZr8DzgYGmFk18O9ADwB3/ykwA7gEqAIagRvSFYtIptnd2sbK2p0s39TA8k0NrNi0g9VbdrJ6SyPNrYk96/XKz2Vk/96MH1LCR04ezIh+vRnatyfD+vZkcElP8vP0C16OXDqvGrrmIMsd+Hy69i+SCVrbEqze0siKTQ1Uhgf9yo0NrN7SuOfXfV6OMXJAb0YN6M05x5XtmR41oDdlRQX6RS9plxWdxSLZoLk1wfJNDSxZX8fidfUsXl/Hsg31NLUEv/DNYES/XowtL+KSkwYzpryI48qLGDWgt37ZS6SUCEQOQ0tbgmUb6llYXceSdXUsXl9H5cYGWtqCX/l9CvIYN6SYT04ewbghxRxXXsSxZX3omZ8bceQi76VEIJKCmvom5q/ZxptrtjN/zTYWVdexO2zLL+3VgxOHlHDjWaM4cUgJJw4tYUS/XuTkqElHsoMSgUgHbQln6fp65qzeuufgv277LgDyc3MYP7SY684YwYSKUk4ZVsqwvj3Vji9ZTYlAYq+1LcGS9fW8vnILb6zaypzVW2kIb7oaUlLIhBF9ufGsUUyoKGX8kGIK8tS8I92LEoHETlvCeWtdHX9/Zwuvr9zCvHe3sWN3cOAfPbA3l54yhCmj+jFlVH8GlRRGHK1I+ikRSCys376LV1bU8vLyzbxatZm6XS0AjCnrw8cmDGXK6H5MHtWPsiId+CV+lAikW9rV3MbrK7fw8opaXl5eyzu1OwEoLy7ggnHlfGDsQN53TH8G9CmIOFKR6CkRSLdRU9/EC2/X8PzSTbxatZndrQkK8nKYMro/10yu4INjBzKmrI86dkU6UCKQrOXuvL2xgeeXbuL5t2tYuHY7AMP69uSTUyr48PFlnD6yH4U91LkrciBKBJJV3J2F1XU8vWg9f1m8keptwWWdpw4v5Y4Lj+O8E8oZW65f/SKHQolAMp67s6i6jhlvbeDPizawbvsueuQaZx07gNvOOZYPH19GWbE6eUUOlxKBZKzKjQ38/s1qnl60geptu8jLMT4wZgBfOn8s559QTkmvHlGHKNItKBFIRtm8YzfTF6zn929Ws3hdPXk5xlljBnD7uWO4YNwgHfxF0kCJQCK3u7WNF5bV8Pv51cyqrKU14Zw0tIS7Lx3HpacMob8u8RRJKyUCicyqzTv53ew1PDF3LdsaWygvLuCmD4ziyonDGFteFHV4IrGhRCBdqqUtwfNLN/HIG2t4tWozeTnGBePL+cfTKzjr2AHkasROkS6nRCBdoqahid/8/V1+N2cttQ27GVrak69eMJZPTBquK35EIqZEIGlVubGBX7y6kj++uZ6WRIJzjivjujMq+NDYMv36F8kQSgRy1Lk7r6zYzM9fXcXLy2vp2SOXqycP54b3j2LUgN5RhyciHSgRyFGTSDjPLNnIf75YxbIN9QwsKuCOC4/j2ikVlPbKjzo8EdkPJQI5Ym0J58+L1vPAzCqWb9rB6AG9uf+qk7ns1CF6iItIFlAikMPW2pZg+sL1/NfMKlbW7mRMWR9+dM0EPnLSYLX/i2QRJQI5ZO7OM4s3cv9fK1lZu5PjBxXx42snctH4QXpgu0gWUiKQQ/LaO5v57jOVLFy7nWPL+vDT607jgnHlSgAiWUyJQFKyeF0d9z1bycvLaxlcUsh9V57MxycOJS83J+rQROQIKRHIAdXUN3Hfs5U8Oa+akp49+NdLjufTZ47Uw15EuhElAunU7tY2fvm31fznCytobktwywdHc+s5x1LSU6N/inQ3SgSyD3fnhWU1fOvppaze0si5x5fxjY+O041gIt2YEoHssXZrI//21GJmVdZyzMDe/OqG0zn7uLKowxKRNFMiEFraEkx7dRU/eH45uWZ84yMncP37RtJDHcEisaBEEHML1m7na79/i2Ub6jnvhHLuvXw8Q0p7Rh2WiHQhJYKYamxu5b5nKvn131dTVlTAT6+byIXjB2Gm+wFE4iaticDMLgL+P5AL/Nzdv9NheQXwa6A0XOdOd5+RzpgE5q7eyleeWMi7Wxr51BkjuOOi4ygu1NVAInGVtkRgZrnAA8D5QDUwx8ymu/vSpNW+ATzu7j8xs3HADGBkumKKu6aWNn7w3HIefGUlQ0t78rubz+DMY/pHHZaIRCydZwSTgSp3XwlgZo8ClwPJicCB4nC6BFifxnhibfG6Or78+AKWb9rBNZMr+PpHTqBPgVoGRSS9iWAosDZpvhqY0mGdu4G/mtkXgN7AeWmMJ5YSCednr6zk/mcr6d8nX5eEish7RP2T8BrgV+7+PTM7E3jYzE5090TySmY2FZgKUFFREUGY2Wnzjt185fGFvLS8lovGD+I7V56kB8SIyHukMxGsA4YnzQ8Ly5LdBFwE4O5/N7NCYABQk7ySuz8IPAgwadIkT1fA3cnfqjbzxccWULerhW9ecSLXTanQFUEi0ql03jE0BxhjZqPMLB+4GpjeYZ01wLkAZnYCUAjUpjGmbq8t4Xz/r5Vc94s3KC7M46nPv59PnTFCSUBE9ittZwTu3mpmtwHPElwaOs3dl5jZvcBcd58OfAX4mZl9iaDj+DPurl/8h6musYXbH3uTWZW1XDlxGN+8Yjy98qNu/RORTJfWo0R4T8CMDmV3JU0vBd6fzhji4u2N9dzy8DzWb9/Ft644kWvVFCQiKdLPxW7gz4vWc8cTiygqzOPRqWdy2oi+UYckIllEiSCLuTs/eH4FP3phBaeN6MtPrp1IWXFh1GGJSJZRIshSu1vb+D9PLuKpBev5xKRhfOuKk8jP02ihInLolAiy0Ladzdzy8Dxmr97KHRcex61nH6P+ABE5bEoEWebdLTv5zC/nsG77Lv7zmglcesqQqEMSkSynRJBFlm2o51O/mE1bIsFvPzuFSSP7RR2SiHQDSgRZYt6727jhl7PplR9cGXRsWVHUIYlIN6FEkAVeWVHL1IfmUV5cwMM3TWF4v15RhyQi3YgSQYZ7fukmbn1kPqMH9uahmyZTVqTLQ0Xk6FIiyGAvLNvE5x6Zx7ghJTx0w2RKeukpYiJy9CkRZKiZlTV87jfzOWFwMQ/dOJmSnkoCIpIeugMpA720vJZbHp7HmPI+PHzjFCUBEUkrJYIMM3vVVqY+NJdjBvbhNzdNUXOQiKSdEkEGqdzYwGd/PYehfXvym5sm07e3niYmIumnRJAh1m3fxfXTZlPYI5eHbpxM/z4FUYckIjGhzuIMsG1nM5/+xRvsbG7l8VvOZFhf3ScgIl1HiSBiza0Jbnl4Hmu37eKhGydzwuDiqEMSkZhR01CE3J27nlrM7NVbuf+qkzljdP+oQxKRGDpoIrDAdWZ2VzhfYWaT0x9a9/er11bz6Jy1fP6cY7j81KFRhyMiMZXKGcGPgTOBa8L5BuCBtEUUEy8vr+Wbf17K+ePK+cr5x0UdjojEWCp9BFPcfaKZvQng7tvMTNc1HoHqbY184XdvMra8iB/+46nk5OihMiISnVTOCFrMLBdwADMbCCTSGlU31tya4Lbfvkki4fz3p06jd4H660UkWqkkgh8BfwDKzOw/gFeBb6c1qm7sO395mwVrt3PfVSczon/vqMMRETl405C7P2Jm84BzAQOucPdlaY+sG3pm8Uam/W0Vn3nfSC4+aXDU4YiIACkkAjM7A1ji7g+E88VmNsXd30h7dN3I2q2N3PHkQk4ZVsLXLjk+6nBERPZIpWnoJ8COpPkdYZmkKJFwvvrEQtzhvz45kYK83KhDEhHZI5VEYO7u7TPunkB3JB+SX7y6ijdWbeWuS8fpMZMiknFSSQQrzeyfzaxH+LodWJnuwLqLyo0N3P9sJeePK+cfThsWdTgiIu+RSiL4J+B9wDqgGpgCTE1nUN1Fc2uCLz22gKLCPP7vx0/CTPcLiEjmSeWqoRrg6i6Ipdt5YGYVSzfU8+CnTmOAhpUWkQyVylVDA4GbgZHJ67v7jekLK/tV1TTw41lVXHbKEC4YPyjqcERE9iuVTt+ngFeA54G29IbTPSQSzr/+fjG98vP4t4+OizocEZEDSiUR9HL3f0l7JN3I43PXMnv1Vr575UkMLFKTkIhktlQ6i/9sZpekPZJuorZhN9+esYzJo/rxiUnDow5HROSgUkkEtxMkg11mVm9mDWZWn8rGzewiM6s0syozu3M/63zCzJaa2RIz++2hBJ+J/uPppTS1JPj2x3SVkIhkh1SuGio6nA2HI5Y+AJxPcNnpHDOb7u5Lk9YZA3wNeH84vHXZ4ewrU8x7dyt/XLCez59zDMeW9Yk6HBGRlKR0h7CZ9QXGAIXtZe7+8kE+NhmocveV4TYeBS4HliatczPwgLtvC7dZk3romSWRcO7501LKiwu49exjow5HRCRlqTyq8rPAy8CzwD3h+90pbHsosDZpvjosSzYWGGtmfzOz183sov3EMNXM5prZ3Nra2hR23fX+Z341i6rruPPi4/WMARHJKqn2EZwOvOvu5wATgO1Haf95BGcaZxM8CvNnZlbacSV3f9DdJ7n7pIEDBx6lXR89O3a3ct+zlUyoKOXyU/TsYRHJLqkkgiZ3bwIwswJ3fxtI5SG764Dky2aGhWXJqoHp7t7i7quA5QSJIas8MLOK2obd/Pul4/XYSRHJOqkkgurwV/ofgefM7Cng3RQ+NwcYY2ajwmccXw1M77DOHwnOBjCzAQRNRVk1oN3GuiamvbqKK04dwqnDS6MOR0TkkKVy1dDHwsm7zWwmUAI8k8LnWs3sNoI+hVxgmrsvMbN7gbnuPj1cdoGZLSW4a/kOd99ymHWJxI9eXEHCna9ckMpJkohI5tlvIjCzYnevN7N+ScVvhe99gK0H27i7zwBmdCi7K2nagS+Hr6yzavNOHpuzlmunVOg5AyKStQ50RvBb4KPAPMAJnlec/D467dFluO8/t5z83Bxu+7AuFxWR7LXfRODuH7Xg1tgPufuaLowpKyxZX8efFgY3j5UVFR78AyIiGeqAncVh083TXRRLVvnBc8sp6dmDqR88JupQRESOSCpXDc03s9PTHkkWWbK+jueX1XDTWaMo6dkj6nBERI5IKrfATgGuNbN3gZ2EfQTufnJaI8tgP575DkUFeVz/vpFRhyIicsRSSQQXpj2KLFJVs4MZizdw69nH6GxARLqFVO4jeBcgHBk09r2iP55VRWFeLje+f1TUoYiIHBWpDDp3mZmtAFYBLwGrgb+kOa6MtHZrI08tWM8np1TQXw+jF5FuIpXO4m8CZwDL3X0UcC7welqjylDT/raKHIObPxD7WyhEpBtJJRG0hMM+5JhZjrvPBCalOa6MU9/UwuNz1nLpyUMYVBL7FjIR6UZS6SzebmZ9CJ5J8IiZ1RBcPRQrj81ey87mNm48S30DItK9pHJGcDnQCHyJYLC5d4BL0xlUpmltS/Cr11YzZVQ/ThxaEnU4IiJHVSqJ4BZgsLu3uvuv3f1H2TZC6JF6ZslG1m3fxU06GxCRbiiVRFAE/NXMXjGz28ysPN1BZZppr65iRP9enHtC7KouIjFw0ETg7ve4+3jg88Bg4CUzez7tkWWIZRvqmb9mO586YwS5evqYiHRDqZwRtKsBNgJbgLL0hJN5fvvGGvLzcrjqtGFRhyIikhap3FB2q5nNAl4A+gM3x2WcocbmVv745jo+ctJgSnvlRx2OiEhapHL56HDgi+6+IM2xZJw/L9xAw+5WPjmlIupQRETSJpWxhr7WFYFkokdmr2FMWR8mjegbdSgiImlzKH0EsbJkfR0L127nmskVBA9qExHpnpQI9uPJedXk5+bw8YlDow5FRCStUukjAMDMipPXd/etaYkoA7S2JfjTwvWce0KZOolFpNs7aCIws1uAe4AmwMNiB7rtEJyvVG1m845mrpigswER6f5SOSP4KnCiu29OdzCZ4g/z11HaqwfnHBeb2yVEJMZS6SN4h2DQuVjYsbuVvy7dyEdOGkx+nrpQRKT7S+WM4GvAa2b2BrC7vdDd/zltUUXo2cUbaWpJqJNYRGIjlUTw38CLwFtAIr3hRO+PC9YxvF9PJlbo3gERiYdUEkEPd/9y2iPJANt2NvPaO1uY+sHRundARGIjlUbwv5jZVDMbbGb92l9pjywCzy3bRFvCufjEQVGHIiLSZVI5I7gmfE8eaqJbXj76zOKNDC3tyUl6CpmIxEgqYw3F4rFc9U0tvLKiluvPHKlmIRGJlVRuKPt0Z+Xu/tDRDyc6Ly6roaXNufgkNQuJSLyk0jR0etJ0IXAuMB/oVongL4s3UF5cwIThulpIROIllUdVfiHpdTMwEeiTysbN7CIzqzSzKjO78wDrXWlmbmaTUg/96Nnd2sYrKzZz3gnl5OhxlCISM4dz6+xO4KD9BmaWCzwAXAyMA64xs3GdrFcE3A68cRixHBVzVm2jsbmNDx+vISVEJH5S6SP4E3sHm8shOKg/nsK2JwNV7r4y3M6jwOXA0g7rfRP4LnBHijEfdS++XUN+Xg5nHtM/qhBERCKTSh/B/0uabgXedffqFD43FFibNF8NTElewcwmAsPd/WkziywRzKqs4czR/emVn/Ko3CIi3cZ+j3xmdixQ7u4vdSh/v5kVuPs7R7JjM8sBvg98JoV1pwJTASoqju7zg1dv3snKzTv59Jkjjup2RUSyxYH6CH4I1HdSXh8uO5h1BA++bzcsLGtXBJwIzDKz1cAZwPTOOozd/UF3n+TukwYOHJjCrlM3q7IGgHPUPyAiMXWgRFDu7m91LAzLRqaw7TnAGDMbZWb5wNXA9KTt1Ln7AHcf6e4jgdeBy9x97qFU4Ej97Z0tjOjfixH9e3flbkVEMsaBEkHpAZb1PNiG3b0VuA14FlgGPO7uS8zsXjO77JCiTJO2hPP6yi28T53EIhJjB+odnWtmN7v7z5ILzeyzwLxUNu7uM4AZHcru2s+6Z6eyzaNpyfo6GppaOWO0EoGIxNeBEsEXgT+Y2bXsPfBPAvKBj6U5ri7x2jtbAHTZqIjE2n4TgbtvAt5nZucQdOoCPO3uL3ZJZF3gtXe2MKasD2VFhVGHIiISmVRGH50JzOyCWLpUa1uCuau3cuXEYVGHIiISqdg+nX35ph00Nrdx2ggNMici8RbbRDB/zTYAPZtYRGIv1omgf+98hvc76JWwIiLdWmwTwZtrtjOhoq+eRiYisRfLRLC9sZlVm3cycURp1KGIiEQulolg6YZgCCU9pF5EJKaJ4O0NDQAcP6g44khERKIXz0SwsZ4BffIZWFQQdSgiIpGLaSJo0NmAiEgodomgLeEs39TA8YOKog5FRCQjxC4RrN3aSFNLgrFKBCIiQAwTwZqtjQCM1INoRESAGCeCin69Io5ERCQzxC4RrN3aSH5eDmW6YkhEBIhhIliztZHhfXuSk6OhJUREIKaJQM1CIiJ7xS4RrN3ayLC+SgQiIu1ilQiaWtqob2plUIkeTSki0i5WiaC2YTcAA/uoo1hEpF28EsGOMBHoiiERkT3ilQgalAhERDpSIhARibnYJQIz6Nc7P+pQREQyRqwSwbbGZooLe9AjN1bVFhE5oFgdERuaWikqzIs6DBGRjBKzRNBCcWGPqMMQEckosUoE9TojEBF5j3glgl0tFOmMQERkH7FKBA1NrRTrjEBEZB8xSwQtahoSEekgVomgqSVBYX5u1GGIiGSUtCYCM7vIzCrNrMrM7uxk+ZfNbKmZLTKzF8xsRLpicXea2xIU6B4CEZF9pO2oaGa5wAPAxcA44BozG9dhtTeBSe5+MvAkcF+64mluSwCQn6dEICKSLJ1HxclAlbuvdPdm4FHg8uQV3H2muzeGs68Dw9IVTHOrEoGISGfSeVQcCqxNmq8Oy/bnJuAvnS0ws6lmNtfM5tbW1h5WMHsSgZqGRET2kRFHRTO7DpgE3N/Zcnd/0N0nufukgQMHHtY+9jYNqbNYRCRZOq+lXAcMT5ofFpbtw8zOA74OfMjdd6crGDUNiYh0Lp1HxTnAGDMbZWb5wNXA9OQVzGwC8N/AZe5ek8ZYlAhERPYjbUdFd28FbgOeBZYBj7v7EjO718wuC1e7H+gDPGFmC8xs+n42d8R2q49ARKRTab3N1t1nADM6lN2VNH1eOvefrL2PoEBnBCIi+4jNUVFNQyIinYvNUbEt4QDk5VjEkYiIZJbYJYJcJQIRkX3EJhEkPEgEZkoEIiLJYpMIwjygMwIRkQ5ikwjam4aUB0RE9hWbRNDeNJSjpiERkX0oEYiIxFyMEkHwrj4CEZF9xSYRqI9ARKRzsUkEe5qGlAlERPYRv0SgPgIRkX3EJxEEQw2Rq0QgIrKP2CSCtj13FkcciIhIholNInDXWEMiIp2JTSIIH0egPgIRkQ5ikwj2XjUUcSAiIhkmNodFXTUkItK5+CSC9ucRKBGIiOwjNomgLRxiQmcEIiL7ik0icPURiIh0KjaHxb1jDemMQEQkWWwSwagBvfnISYPJy1UiEBFJlhd1AF3lgvGDuGD8oKjDEBHJOLE5IxARkc4pEYiIxJwSgYhIzCkRiIjEnBKBiEjMKRGIiMScEoGISMwpEYiIxJy1j8GTLcysFnj3MD8+ANh8FMOJkuqSmbpLXbpLPUB1aTfC3Qd2tiDrEsGRMLO57j4p6jiOBtUlM3WXunSXeoDqkgo1DYmIxJwSgYhIzMUtETwYdQBHkeqSmbpLXbpLPUB1OahY9RGIiMh7xe2MQEREOlAiEBGJudgkAjO7yMwqzazKzO6MOp6DMbPVZvaWmS0ws7lhWT8ze87MVoTvfcNyM7MfhXVbZGYTI459mpnVmNnipLJDjt3Mrg/XX2Fm12dQXe42s3Xhd7PAzC5JWva1sC6VZnZhUnmkf39mNtzMZprZUjNbYma3h+VZ970coC7Z+L0UmtlsM1sY1uWesHyUmb0RxvWYmeWH5QXhfFW4fOTB6pgSd+/2LyAXeAcYDeQDC4FxUcd1kJhXAwM6lN0H3BlO3wl8N5y+BPgLYMAZwBsRx/5BYCKw+HBjB/oBK8P3vuF03wypy93AVztZd1z4t1UAjAr/5nIz4e8PGAxMDKeLgOVhvFn3vRygLtn4vRjQJ5zuAbwR/ns/Dlwdlv8U+Fw4fSvw03D6auCxA9Ux1TjickYwGahy95Xu3gw8ClwecUyH43Lg1+H0r4Erksof8sDrQKmZDY4gPgDc/WVga4fiQ439QuA5d9/q7tuA54CL0h58B/upy/5cDjzq7rvdfRVQRfC3F/nfn7tvcPf54XQDsAwYShZ+Lweoy/5k8vfi7r4jnO0Rvhz4MPBkWN7xe2n/vp4EzjUzY/91TElcEsFQYG3SfDUH/sPJBA781czmmdnUsKzc3TeE0xuB8nA6G+p3qLFnep1uC5tMprU3p5AldQmbEyYQ/PrM6u+lQ10gC78XM8s1swVADUFifQfY7u6tncS1J+ZweR3QnyOsS1wSQTY6y90nAhcDnzezDyYv9OB8MCuv/c3m2EM/AY4BTgU2AN+LNJpDYGZ9gP8Bvuju9cnLsu176aQuWfm9uHubu58KDCP4FX98V8cQl0SwDhieND8sLMtY7r4ufK8B/kDwB7KpvcknfK8JV8+G+h1q7BlbJ3ffFP7PmwB+xt5T8Iyui5n1IDhwPuLuvw+Ls/J76awu2fq9tHP37cBM4EyCpri8TuLaE3O4vATYwhHWJS6JYA4wJuyJzyfoZJkecUz7ZWa9zayofRq4AFhMEHP7VRrXA0+F09OBT4dXepwB1CWd7meKQ439WeACM+sbnuJfEJZFrkP/y8cIvhsI6nJ1eGXHKGAMMJsM+PsL25F/ASxz9+8nLcq672V/dcnS72WgmZWG0z2B8wn6PGYCV4Wrdfxe2r+vq4AXwzO5/dUxNV3ZQx7li+AqiOUE7W9fjzqeg8Q6muAKgIXAkvZ4CdoCXwBWAM8D/XzvlQcPhHV7C5gUcfy/Izg1byFoq7zpcGIHbiTo9KoCbsigujwcxroo/B9wcNL6Xw/rUglcnCl/f8BZBM0+i4AF4euSbPxeDlCXbPxeTgbeDGNeDNwVlo8mOJBXAU8ABWF5YThfFS4ffbA6pvLSEBMiIjEXl6YhERHZDyUCEZGYUyIQEYk5JQIRkZhTIhARiTklAukSZuZm9r2k+a+a2d1Hadu/MrOrDr7mEe/nH8xsmZnNTPe+omZm/xp1DNJ1lAikq+wGPm5mA6IOJFnS3ZupuAm42d3PSVc8GUSJIEaUCKSrtBI8b/VLHRd0/EVvZjvC97PN7CUze8rMVprZd8zs2nD89rfM7JikzZxnZnPNbLmZfTT8fK6Z3W9mc8KByG5J2u4rZjYdWNpJPNeE219sZt8Ny+4iuJHpF2Z2fyef+ZfwMwvN7Dth2alm9nq47z/Y3rH+Z5nZD8J4l5nZ6Wb2ewvG9/9WuM5IM3vbzB4J13nSzHqFy841szfD/U0zs4KwfLWZ3WNm88Nlx4flvcP1Zoefuzws/0y432fCfd8Xln8H6GnBmP6PhJ9/OqzbYjP7x0P43iUbdPWddHrF8wXsAIoJnrNQAnwVuDtc9ivgquR1w/ezge0E488XEIydck+47Hbgh0mff4bgh80YgjuAC4GpwDfCdQqAuQRjtZ8N7ARGdRLnEGANMBDIA14ErgiXzaKTu7YJBgZ8DegVzrffnbsI+FA4fW9SvLPYO+7/7cD6pDpWE9ztO5Lg7tn3h+tNC//NCglGmRwblj9EMOga4b/tF8LpW4Gfh9PfBq4Lp0sJ7qTtDXyG4HkCJeF23wWGJ38H4fSVwM+S5kui/nvS6+i+dEYgXcaDESIfAv75ED42x4Px53cT3D7/17D8LYKDZbvH3T3h7isIDm7HE4yD82kLhvh9g+AAOyZcf7YH47Z3dDowy91rPRjm9xGCh9McyHnAL929MaznVjMrAUrd/aVwnV932E77mDZvAUuS6riSvYOHrXX3v4XTvyE4IzkOWOXuy/ez3fbB5Oax99/nAuDO8N9hFsFBvyJc9oK717l7E8HZ0YhO6vcWcL6ZfdfMPuDudQf595AscyjtoyJHww+B+cAvk8paCZspzSyH4GlR7XYnTSeS5hPs+/fbcawUJxgv5wvuvs+gaGZ2NsEZQZSS69Gxju316qxOqW63LWk7Blzp7pXJK5rZlA77Tv7M3p26L7fgUZWXAN8ysxfc/d4UYpEsoTMC6VLuvpXgMXw3JRWvBk4Lpy8jeErTofoHM8sJ+w1GEwy89SzwOQuGLMbMxlowmuuBzAY+ZGYDzCwXuAZ46SCfeQ64IakNv1/4q3mbmX0gXOdTKWynowozOzOc/iTwalivkWZ27CFs91ngC2ZmYXwTUth3S9K/2xCg0d1/A9xP8OhO6UZ0RiBR+B5wW9L8z4CnzGwhQVv/4fxaX0NwEC8G/sndm8zs5wTNI/PDg2Atex/51yl332DBQ8xnEvySftrdnzrIZ54xs1OBuWbWDMwguOrmeuCnYYJYCdxwiHWqJHgo0TSCZpufhPW6AXgivOJpDsEzbQ/kmwRnYovCM65VwEcP8pkHw/XnEzTn3W9mCYJRWD93iPWQDKfRR0UykAWPYPyzu58YdSzS/alpSEQk5nRGICISczojEBGJOSUCEZGYUyIQEYk5JQIRkZhTIhARibn/Be1K8t8LIo1AAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# First verfiy the ideal number of PCA components to not lose much information. \n",
    "# Try to retain 90% information, so look where the curve starts to flatten.\n",
    "# Remember that the n_components must be lower than the number of rows or columns (features)\n",
    "pca_test = PCA(n_components=3000) \n",
    "#pca_test.fit(trainX)\n",
    "pca_test.fit(data)\n",
    "plt.plot(np.cumsum(pca_test.explained_variance_ratio_))\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cum variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick the optimal number of components. This is how many features we will have \n",
    "#for our machine learning\n",
    "\n",
    "n_PCA_components = 1000\n",
    "pca = PCA(n_components=n_PCA_components)\n",
    "train_PCA = pca.fit_transform(data)\n",
    "test_PCA = pca.transform(data) #Make sure you are just transforming, not fitting.\n",
    "\n",
    "#If we want 90% information captured we can also try ...\n",
    "#pca=PCA(0.9)\n",
    "#principalComponents = pca.fit_transform(trainX)\n",
    "#print(principalComponents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\balaj\\anaconda3\\envs\\GPU_ML\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(n_PCA_components,)))\n",
    "model.add(Dense(1008,activation='relu'))\n",
    "model.add(Dense(1008,activation='sigmoid'))\n",
    "model.add(Dense(1008,activation='sigmoid'))\n",
    "#model.add(Dense(1008,activation='relu'))\n",
    "model.add(Dense(1096, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./HOG_NN/HOGNN_Muzzlepatterns.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pop()\n",
    "model.add(Dense(1100, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (16439, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21816\\3853274293.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m           \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m           )\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\balaj\\anaconda3\\envs\\GPU_ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\Users\\balaj\\anaconda3\\envs\\GPU_ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\balaj\\anaconda3\\envs\\GPU_ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2535\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2536\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2537\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2539\u001b[0m       \u001b[1;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\balaj\\anaconda3\\envs\\GPU_ML\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    713\u001b[0m         raise ValueError('You are passing a target array of shape ' +\n\u001b[0;32m    714\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m                          \u001b[1;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m                          \u001b[1;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                          \u001b[1;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are passing a target array of shape (16439, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./models/vrindhavan_model_weights.h5\", \n",
    "                             monitor='categorical_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=True, \n",
    "                             mode='auto', \n",
    "                             #save_freq=1\n",
    "                             )\n",
    "\n",
    "early = EarlyStopping(monitor='categorical_accuracy', \n",
    "                      min_delta=0, \n",
    "                      patience=10, \n",
    "                      verbose=1, \n",
    "                      mode='auto')\n",
    "Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.16,\n",
    "    beta_2=0.099,\n",
    "    epsilon=3e-04,\n",
    "    amsgrad=True,\n",
    "    name=\"Adam\",\n",
    "    \n",
    ")\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy'])\n",
    "\n",
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "#Fit the model. Do not forget to use on-hot-encoded Y values. \n",
    "model.fit(train_PCA,toh, \n",
    "          epochs=10, \n",
    "          verbose=1,\n",
    "          callbacks=[checkpoint]\n",
    "          )\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(\"Total execution time with PCA is: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./HOG_NN/HOGNN_Muzzlepatterns.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [1072 1073 1352 1353 1463 1464 1466 1470 1471 1473 1476 2181 2373 3145\n 3147 3150 3151 3152 3153 3315 3319 3329 3331 3335 3336 3339 3342 3351\n 3354 3357 3360 3363 3364 3365 3367 3380 3381 3384 3390 3391 3392 3396\n 3400 3403 3408 3411 3413 3417 3418 3423 3424 3426 3428 3431 3432 3436\n 3438 3439 3441 3443 3444 3447 3450 3451 3455 3464 3471 3472 3474 3475\n 3477 3478 3480 3481 3483 3487 3491 3505 3511 3513 3515 3516 3531 3534\n 3541 3543 3550 3551 3553 3556 3560 3563 3573 3575 3579 3582 3587 3589\n 3590 3591 3595 3598 3602 3603 3607 3609 3612 3613 3619 3626 3629 3630\n 3632 3636 3637 3638 3643 3645 3647 3648 3659 3662 3665 3669 3671 3674\n 3675 3676 3682 3684 3687 3688 3690 3692 3697 3698 3700 3702 3705 3709\n 3710 3711 3712 3717 3718 3722 3726 3727 3728 3731 3734 3735 3736 3737\n 3748 3752 3753 3756 3757 3761 3763 3766 3767 3771 3773 3774 3775 3777\n 3778 3779 3783 3789 3794 3798 3803 3805 3811 3814 3816 3817 3818 3819\n 3820 3824 3826 3834 3836 3842 3843 3844 3846 3847 3850 3856 3858 3861\n 3864 3865 3868 3870 3871 3875 3876 3878 3883 3888 3889 3893 3899 3900\n 3901 3910 3912 3913 3915 3916 3917 3919 3920 3922 3925 3926 3927 3930\n 3931 3932 3935 3937 3943 3944 3948 3953 3957 3961 3963 3966 3971 3972\n 3973 3975 3978 3979 3982 3985 3990 3992 3994 3995 3997 3999 4013 4878\n 4879 5022 5031 5037 5058 5065 5066 5082 5089 5091 5094 5095 5096 5111\n 5120 5121 5122 5127 5128 5133 5134 5157 5158 5162 5163 5164 5165 5183\n 5185 5187 5189 5191 5199 5200 5201 5216 5217 5219 5220 5223 5225 5227\n 5231 5236 5251 5252 5258 5259 5262 5269 5270 5272 5273 5288 5290 5296\n 5301 5303 5306 5311 5313 5316 5318 5320 5360 5377 5378 5379 5702 5857\n 5858 5859 5861 5864 5866 5867 5868 5869 5871 5873 5877 5885 5887 5888\n 5889 5891 5892 5894 5895 5898 5899 5901 5908 5909 5910 5913 5914 6039\n 6055 6112 6138 6162 6165 6168 6170 6171 6180 6184 6256 6260 6267 6268\n 6269 6271 6272 6287 6289 6290 6291 6292 6294 6296 6297 6299 6300 6304\n 6306 6309 6323 6324 6329 6330 6331 6334 6335 6336 6338 6340 6345 6346\n 6351 6352 6355 6359 6360 6363 6365 6384 6385 6388 6392 6401 6403 6404\n 6406 6409 6411 6413 6418 6429 6433 6434 6436 6438 6439 6440 6441 6443\n 6446 6452 6454 6456 6457 6460 6464 6465 6468 6473 6488 6489 6490 6491\n 6492 6494 6498 6500 6501 6502 6503 6513 6514 6515 6516 6517 6519 6522\n 6524 6527 6528 6529 6530 6531 6535 6536 6540 6541 6542 6544 6546 6548\n 6553 6554 6562 6563 6566 6572 6586 6587 6590 6596 6597 6616 6618 6619\n 6621 6622 6624 6627 6636 6637 6638 6640 6647 6648 6649 6650 6652 6653\n 6654 6656 6661 6690 6699 6700 6703 6705]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15948\\35513584.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpredict_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_PCA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredict_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpredict_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\balaj\\anaconda3\\envs\\GPU_ML\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y contains previously unseen labels: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [1072 1073 1352 1353 1463 1464 1466 1470 1471 1473 1476 2181 2373 3145\n 3147 3150 3151 3152 3153 3315 3319 3329 3331 3335 3336 3339 3342 3351\n 3354 3357 3360 3363 3364 3365 3367 3380 3381 3384 3390 3391 3392 3396\n 3400 3403 3408 3411 3413 3417 3418 3423 3424 3426 3428 3431 3432 3436\n 3438 3439 3441 3443 3444 3447 3450 3451 3455 3464 3471 3472 3474 3475\n 3477 3478 3480 3481 3483 3487 3491 3505 3511 3513 3515 3516 3531 3534\n 3541 3543 3550 3551 3553 3556 3560 3563 3573 3575 3579 3582 3587 3589\n 3590 3591 3595 3598 3602 3603 3607 3609 3612 3613 3619 3626 3629 3630\n 3632 3636 3637 3638 3643 3645 3647 3648 3659 3662 3665 3669 3671 3674\n 3675 3676 3682 3684 3687 3688 3690 3692 3697 3698 3700 3702 3705 3709\n 3710 3711 3712 3717 3718 3722 3726 3727 3728 3731 3734 3735 3736 3737\n 3748 3752 3753 3756 3757 3761 3763 3766 3767 3771 3773 3774 3775 3777\n 3778 3779 3783 3789 3794 3798 3803 3805 3811 3814 3816 3817 3818 3819\n 3820 3824 3826 3834 3836 3842 3843 3844 3846 3847 3850 3856 3858 3861\n 3864 3865 3868 3870 3871 3875 3876 3878 3883 3888 3889 3893 3899 3900\n 3901 3910 3912 3913 3915 3916 3917 3919 3920 3922 3925 3926 3927 3930\n 3931 3932 3935 3937 3943 3944 3948 3953 3957 3961 3963 3966 3971 3972\n 3973 3975 3978 3979 3982 3985 3990 3992 3994 3995 3997 3999 4013 4878\n 4879 5022 5031 5037 5058 5065 5066 5082 5089 5091 5094 5095 5096 5111\n 5120 5121 5122 5127 5128 5133 5134 5157 5158 5162 5163 5164 5165 5183\n 5185 5187 5189 5191 5199 5200 5201 5216 5217 5219 5220 5223 5225 5227\n 5231 5236 5251 5252 5258 5259 5262 5269 5270 5272 5273 5288 5290 5296\n 5301 5303 5306 5311 5313 5316 5318 5320 5360 5377 5378 5379 5702 5857\n 5858 5859 5861 5864 5866 5867 5868 5869 5871 5873 5877 5885 5887 5888\n 5889 5891 5892 5894 5895 5898 5899 5901 5908 5909 5910 5913 5914 6039\n 6055 6112 6138 6162 6165 6168 6170 6171 6180 6184 6256 6260 6267 6268\n 6269 6271 6272 6287 6289 6290 6291 6292 6294 6296 6297 6299 6300 6304\n 6306 6309 6323 6324 6329 6330 6331 6334 6335 6336 6338 6340 6345 6346\n 6351 6352 6355 6359 6360 6363 6365 6384 6385 6388 6392 6401 6403 6404\n 6406 6409 6411 6413 6418 6429 6433 6434 6436 6438 6439 6440 6441 6443\n 6446 6452 6454 6456 6457 6460 6464 6465 6468 6473 6488 6489 6490 6491\n 6492 6494 6498 6500 6501 6502 6503 6513 6514 6515 6516 6517 6519 6522\n 6524 6527 6528 6529 6530 6531 6535 6536 6540 6541 6542 6544 6546 6548\n 6553 6554 6562 6563 6566 6572 6586 6587 6590 6596 6597 6616 6618 6619\n 6621 6622 6624 6627 6636 6637 6638 6640 6647 6648 6649 6650 6652 6653\n 6654 6656 6661 6690 6699 6700 6703 6705]"
     ]
    }
   ],
   "source": [
    "##Predict on test dataset\n",
    "predict_test = model.predict(test_PCA)\n",
    "predict_test = np.argmax(predict_test, axis=1)\n",
    "predict_test = le.inverse_transform(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3288, 1000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_PCA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\balaj\\anaconda3\\envs\\GPU_ML\\lib\\site-packages\\sklearn\\metrics\\_classification.py:217: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    }
   ],
   "source": [
    "##Print overall accuracy\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(test_labels, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix - verify accuracy of each class\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#testY=str(testY)\n",
    "cm = confusion_matrix(test_labels, predict_test)\n",
    "#print(cm)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____0.bead black____\n",
    "____1.bead_flat____\n",
    "____2.bead colored____\n",
    "____3.flat____\n",
    "____4.flat_color____\n",
    "____5.Valley____\n",
    "____6.valley colored____\n",
    "____7.bead valley____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check results on a few select images\n",
    "n=np.random.randint(0,testX.shape[0])\n",
    "print(n)\n",
    "val = testX[n]\n",
    "print(val.shape)\n",
    "x = np.expand_dims(val, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "print(x.shape)\n",
    "# #Expand dims so the input is (num images, x, y, c)\n",
    "input_img_feature=x\n",
    "input_img_PCA = pca.transform(input_img_feature)\n",
    "prediction_img = model.predict(input_img_PCA)\n",
    "prediction_img = np.argmax(prediction_img, axis=1)\n",
    "print(prediction_img)\n",
    "prediction_img = le.inverse_transform(prediction_img)  #Reverse the label encoder to original name\n",
    "print(\"The prediction for this image is: \", prediction_img)\n",
    "print(\"The actual label for this image is: \", test_labels[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagepath='./path/Dataset/Group_Testing/237/admingaushala_Cow_Female_8.png'\n",
    "H=HOG(imagepath,SIZE)\n",
    "x = np.expand_dims(H, axis=0)\n",
    "input_img_feature=X\n",
    "input_img_PCA = pca.transform(input_img_feature)\n",
    "prediction_img = model.predict(input_img_PCA)\n",
    "prediction_img = np.argmax(prediction_img, axis=1)\n",
    "print(prediction_img)\n",
    "prediction_img = le.inverse_transform(prediction_img)  #Reverse the label encoder to original name\n",
    "print(\"The prediction for this image is: \", prediction_img)\n",
    "#print(\"The actual label for this image is: \", test_labels[n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('GPU_ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81d8000a49e387cd3bf236de4b1b0050e70533eb5acd278118fdc7c0243f6cc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
