{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from imutils import paths\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#from tensorflow.keras.layers import Conv2D, Dense, GlobalAveragePooling2D, Flatten, MaxPool2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_function(image):\n",
    "  image = preprocess_input(image)\n",
    "  img = np.array(image, dtype=np.uint8)\n",
    "  grayimg = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  #image = cv2.bitwise_not(image)\n",
    "  #image = cv2.resize(image, (480,360))\n",
    "\n",
    "  #image = np.stack((image,)*3, axis=-1)\n",
    "  #image = np.array(image, dtype=np.uint8)\n",
    "\n",
    "  claheimg = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(9,9))\n",
    "  img = claheimg.apply(grayimg)\n",
    "\n",
    "\n",
    "  (H, hogImage) = feature.hog(img, orientations=11, pixels_per_cell=(6,6),cells_per_block=(17,17), transform_sqrt=True, block_norm=\"L1\", visualize=True) \n",
    "  hogImage = exposure.rescale_intensity(hogImage, out_range=(0, 255))\n",
    "  image = hogImage.astype(\"uint8\")\n",
    "  y = np.expand_dims(image, axis=-1)\n",
    "\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Aug using Image Data Generator \n",
    " \n",
    "train_dataset= ImageDataGenerator( \n",
    "                        #shear_range = 0.2,\n",
    "                        validation_split=0.2,\n",
    "                        #rotation_range=10,\n",
    "                        brightness_range=[0.2,0.5],\n",
    "                        #zoom_range=[0.0,0.1],\n",
    "                        preprocessing_function=preprocessing_function\n",
    "                        )\n",
    "\n",
    "validation_dataset = ImageDataGenerator(\n",
    "                            #shear_range = 0.2,\n",
    "                            validation_split=0.2,\n",
    "                            rotation_range=10,\n",
    "                            #brightness_range=[0.2,0.5],\n",
    "                            zoom_range=[0.0,0.1],\n",
    "                            preprocessing_function=preprocessing_function\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageDataGenerator' object has no attribute 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11764\\1920536723.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'validation \\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImageDataGenerator' object has no attribute 'classes'"
     ]
    }
   ],
   "source": [
    "print(\"Train \\n\",train_dataset.classes)\n",
    "print('validation \\n',validation_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#\n",
    "model.add(tf.keras.layers.Conv2D(input_shape=(480,360,1),\n",
    "                 filters=64,  kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=4096,activation=\"sigmoid\"))\n",
    "model.add(tf.keras.layers.Dense(units=4096,activation=\"sigmoid\"))\n",
    "model.add(tf.keras.layers.Dense(units=n_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#\n",
    "model.add(tf.keras.layers.Conv2D(input_shape=(480,360,1),\n",
    "                 filters=64,  kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=64,  kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "#\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "#\n",
    "model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "#\n",
    "model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "#\n",
    "model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "#\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=4096,activation=\"sigmoid\"))\n",
    "model.add(tf.keras.layers.Dense(units=4096,activation=\"sigmoid\"))\n",
    "model.add(tf.keras.layers.Dense(units=n_class, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x204f147e3c8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name=\"Adam\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model1.h5\", \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='auto', #save_freq=1\n",
    "                             )\n",
    "\n",
    "early = EarlyStopping(monitor='val_acc', \n",
    "                      min_delta=0, \n",
    "                      patience=20, \n",
    "                      verbose=1, \n",
    "                      mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit =model.fit( \n",
    "                      train_dataset,\n",
    "                      #steps_per_epoch=5,\n",
    "                      epochs=40, \n",
    "                      validation_data= validation_dataset)\n",
    "                      #callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history[\"Accuracy\"])\n",
    "plt.plot(model.history['val_Accuracy'])\n",
    "plt.plot(model.history['loss'])\n",
    "plt.plot(model.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Path \n",
    "Results=[]\n",
    "npval=[]\n",
    "dir_path='/content/drive/MyDrive/dataset/test'\n",
    "print(class_names,\"\\n\") \n",
    "\n",
    "for i in os.listdir(dir_path):\n",
    "  img= image.load_img(dir_path+'//'+i,target_size=(450,300))\n",
    "  print(i)\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "  x= image.img_to_array(img)\n",
    "  x=np.expand_dims(x,axis=0)\n",
    "  #imgs=np.vstack([x])\n",
    "\n",
    "  val= resnet_model.predict(x)\n",
    "  npval.append(np.argmax(val))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c522faa5fce6d8b5c33a7e71c77e6295dd637a691eb1b9a0bee8b810b882952"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('imgml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
